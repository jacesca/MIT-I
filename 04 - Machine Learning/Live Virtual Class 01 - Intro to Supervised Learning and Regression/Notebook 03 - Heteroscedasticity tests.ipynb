{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf0e70a7",
   "metadata": {},
   "source": [
    "# Heteroscedasticity tests\n",
    "\n",
    "Because our results are dependent on these statistical assumptions, the results are only correct if our assumptions are correct (at least approximately).\n",
    "\n",
    "- **Homoscedasticity** - If the residuals are symmetrically distributed across the regression line, then the data is said to be homoscedastic.\n",
    "- **Heteroscedasticity** - If the residuals are not symmetrically distributed across the regression line, then the data is said to be heteroscedastic. In this case, the residuals can form a funnel shape or any other non-symmetrical shape\n",
    "\n",
    "The null hypothesis for these tests is that all observations have the same error variance, i.e., the errors are homoscedastic. The tests differ in terms of the type of heteroscedasticity accepted as an alternate hypothesis.\n",
    "\n",
    "**het_goldfeldquandt**: It is used to test the presence of heteroscedasticity in the given data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b01e55",
   "metadata": {},
   "source": [
    "More documentation: [Regression Diagnostics and Specification Tests](https://www.statsmodels.org/stable/diagnostic.html#heteroscedasticity-tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c84a52",
   "metadata": {},
   "source": [
    "Some Heretiscedasticity Tests:\n",
    "    \n",
    "- **het_breuschpagan**: Lagrange Multiplier Heteroscedasticity Test by Breusch-Pagan\n",
    "- **het_white**: Lagrange Multiplier Heteroscedasticity Test by White\n",
    "- **het_goldfeldquandt**: test whether variance is the same in 2 subsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9db0f253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To import the library\n",
    "from statsmodels.stats.diagnostic import het_goldfeldquandt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5d0017",
   "metadata": {},
   "source": [
    "Parameters:\n",
    "\n",
    "- $ y $: array_like. endogenous variable\n",
    "- $ x $: array_like. exogenous variable, regressors\n",
    "- $ idx $: int, default None. column index of variable according to which observations are sorted for the split\n",
    "- $ split $ {int, float}, default None. If an integer, this is the index at which sample is split. If a float in 0<split<1 then split is interpreted as fraction of the observations in the first sample. If None, uses nobs//2.\n",
    "- $ drop $ {int, float}, default None. If this is not None, then observation are dropped from the middle part of the sorted series. If $: 0 < split < 1 $ then split is interpreted as fraction of the number of observations to be dropped. \n",
    "- $ alternative $: {‚Äúincreasing‚Äù, ‚Äúdecreasing‚Äù, ‚Äútwo-sided‚Äù}. The default is increasing. This specifies the alternative for the p-value calculation.\n",
    "- $ store $: bool, default False. Flag indicating to return the regression results\n",
    "\n",
    "Returns:\n",
    "\n",
    "- $ fval $: float. value of the F-statistic\n",
    "- $ pval $: float. p-value of the hypothesis that the variance in one subsample is larger than in the other subsample\n",
    "- $ ordering $: str. The ordering used in the alternative.\n",
    "- $ res_store $: ResultsStore, optional. Storage for the intermediate and final results that are calculated\n",
    "\n",
    "**We will use Goldfeld‚ÄìQuandt test to check homoscedasticity. Hypothesis defined**\n",
    "- Null hypothesis : Residuals are homoscedastic\n",
    "- Alternate hypothesis : Residuals are hetroscedastic\n",
    "\n",
    "> If $ pval < 0.05 $, Ho is rejected, meaning that residuals are hetroscedastic. <br>\n",
    "> If $ pval > 0.05 $, Ho is accepted, meaning that residuals are homoscedastic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b17ec2",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228ac286",
   "metadata": {},
   "source": [
    "# Evaluations required in Linear Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7542d0",
   "metadata": {},
   "source": [
    "* Multicollinearity --> It is required to remove the multicollinearity in the features by removing the columns that not add much value to the model.\n",
    "    - We can validate the multilinearidad with **variance_inflation_factor** (statsmodel). Values greater near 5 show VIF moderate. Greater than 10 High VIF.\n",
    "    - Validating the p-value in the summary of the model applyied. **sm.OLS.summary**. Check \"P>|t|\" column. (statsmodel)\n",
    "        - **P >|t|**: It is the p-value.\n",
    "        - Pr(>|t|) : For each independent feature, there is a null hypothesis and alternate hypothesis.\n",
    "            - Ho : Independent feature is not significant. \n",
    "            - Ha : Independent feature is significant. \n",
    "        - The p-value of less than 0.05 is considered to be statistically significant with a confidence level of 95%. \n",
    "        - If the p-value is less than the significance level of 0.05, then we will reject the null hypothesis in favor of the alternate hypothesis. In other words, we have enough statistical evidence that there is some relationship between the independent variable and the dependent variable.\n",
    "    \n",
    "* Assumpsions:\n",
    "    - (1) Means of residuals should be 0 --> ols_model.resid.mean()\n",
    "    - (2) Normallity of error terms\n",
    "    > Error Terms/Residuals should be normally distributed. <br>\n",
    "    > To chec it we can plot the histogram of residuals. <br>\n",
    "    > If residuals are no normal, apply transformation as: **log**, **arcsinh**, **exponential**, etc.\n",
    "    - (3) Linearity of variables\n",
    "    > Predictor variables must have a linear relation with the dependent variable. <br>\n",
    "    > To test plot the residuals (**ols_model.resid**) and the fitted values (**ols_model.fittedvalues**) to ensure there is no pattern. We can use **sns.residplot**. <br>\n",
    "    > If pattern is found, transformation to the target/dependent variable need to be applied. Ex. log.\n",
    "    - (4) No heteroscedasticity\n",
    "    > Use Goldfeld‚ÄìQuandt (**sms.het_goldfeldquandt** form statsmodel)test to check homoscedasticity. <br>\n",
    "    > Hypothesis defined\n",
    "    > - Null hypothesis : Residuals are homoscedastic\n",
    "    > - Alternate hypothesis : Residuals are hetroscedastic\n",
    "    > Interpretation:\n",
    "    > - If  ùëùùë£ùëéùëô<0.05, Ho is rejected, meaning that residuals are hetroscedastic.\n",
    "    > - If  ùëùùë£ùëéùëô>0.05, Ho is accepted, meaning that residuals are homoscedastic.\n",
    "    > \n",
    "    > To test: <br>\n",
    "    > $$ name = [\"F statistic\", \"p-value\"] $$\n",
    "    > $$ test = sms.het_goldfeldquandt(target, features) $$\n",
    "    > $$ lzip(name, test) $$\n",
    "    > Output Ex:\n",
    "    > $$ [('F statistic', 0.9395156175145154), ('p-value', 0.9790604597916552)] $$\n",
    "    > Check p-value if it is <0.05, in this case it is not, so data is hoscedastic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc484c52",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1863380a",
   "metadata": {},
   "source": [
    "# Ridge Regression\n",
    "\n",
    "Because a general linear or polynomial regression will fail if the independent variables are highly collinear, Ridge regression can be utilized to tackle such situations.\n",
    "\n",
    "When we have more parameters than samples, it is easier to solve problems using Ridge Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebe12bc",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242898b9",
   "metadata": {},
   "source": [
    "# Elastic Net Regression\n",
    "\n",
    "Elastic Net is a regularized regression model that combines ùêø1 and ùêø2 penalties, i.e., lasso and ridge regression. As a result, it performs a more efficient smoothing process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cd562c",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9545da19",
   "metadata": {},
   "source": [
    "# Why should we do feature selection?\n",
    "\n",
    "- Reduces dimensionality\n",
    "- Discards deceptive features; Deceptive features appear to aid learning on the training set but impair generalization\n",
    "- Speeds training/testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e73a6f",
   "metadata": {},
   "source": [
    "-----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
