{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9aefcb52",
   "metadata": {},
   "source": [
    "# Variance inflation factor(VIF)\n",
    "\n",
    "A variance inflation factor (VIF) is a measure of the amount of multicollinearity in regression analysis. Multicollinearity exists when there is a correlation between multiple independent variables in a multiple regression model. This can adversely affect the regression results.\n",
    "\n",
    "[statsmodel python librari related to the variance_inflation_factor](https://www.statsmodels.org/dev/generated/statsmodels.stats.outliers_influence.variance_inflation_factor.html?highlight=vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "566b26e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c44bee4",
   "metadata": {},
   "source": [
    "**KEY TAKEAWAYS**\n",
    "\n",
    "A variance inflation factor (VIF) provides a measure of multicollinearity among the independent variables in a multiple regression model.\n",
    "Detecting multicollinearity is important because while multicollinearity does not reduce the explanatory power of the model, it does reduce the statistical significance of the independent variables. \n",
    "A large VIF on an independent variable indicates a highly collinear relationship to the other variables that should be considered or adjusted for in the structure of the model and selection of independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1e0f25",
   "metadata": {},
   "source": [
    "**Understanding a Variance Inflation Factor (VIF)**\n",
    "\n",
    "A variance inflation factor is a tool to help identify the degree of multicollinearity. Multiple regression is used when a person wants to test the effect of multiple variables on a particular outcome. The dependent variable is the outcome that is being acted upon by the independent variablesâ€”the inputs into the model. Multicollinearity exists when there is a linear relationship, or correlation, between one or more of the independent variables or inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62a1109",
   "metadata": {},
   "source": [
    "### The Problem of Multicollinearity\n",
    "\n",
    "Multicollinearity creates a problem in the multiple regression model because the inputs are all influencing each other. Therefore, they are not actually independent, and it is difficult to test how much the combination of the independent variables affects the dependent variable, or outcome, within the regression model.\n",
    "\n",
    "While multicollinearity does not reduce a model's overall predictive power, it can produce estimates of the regression coefficients that are not statistically significant. In a sense, it can be thought of as a kind of double-counting in the model.\n",
    "\n",
    "In statistical terms, a multiple regression model where there is high multicollinearity will make it more difficult to estimate the relationship between each of the independent variables and the dependent variable. In other words, when two or more independent variables are closely related or measure almost the same thing, then the underlying effect that they measure is being accounted for twice (or more) across the variables. When the independent variables are closely-related, it becomes difficult to say which variable is influencing the dependent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3198c25",
   "metadata": {},
   "source": [
    "### Tests to Solve Multicollinearity\n",
    "\n",
    "To ensure the model is properly specified and functioning correctly, there are tests that can be run for multicollinearity. **The variance inflation factor** is one such measuring tool. Using variance inflation factors **helps to identify the severity of any multicollinearity issues** so that the model can be adjusted. Variance inflation factor **measures how much the behavior (variance) of an independent variable is influenced, or inflated, by its interaction/correlation with the other independent variables**.\n",
    "\n",
    "Variance inflation factors allow a quick measure of how much a variable is contributing to the standard error in the regression. When significant multicollinearity issues exist, the variance inflation factor will be very large for the variables involved. After these variables are identified, several approaches can be used to eliminate or combine collinear variables, resolving the multicollinearity issue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d164440f",
   "metadata": {},
   "source": [
    "### Formula and Calculation of VIF\n",
    "The formula for VIF is:\n",
    "$$ VIF_i = \\frac{1}{1 - {R^2}_i} $$\n",
    "\n",
    "where:\n",
    "- $ {R^2}_i $ : Unadjusted coefficient of determination for regressing the ith independent variable on the remaining ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b1bbad",
   "metadata": {},
   "source": [
    "**What Can VIF Tell You?**\n",
    "\n",
    "When $ {R^2}_i $ is equal to $ 0 $, and therefore, when $ VIF $ or tolerance is equal to $ 1 $, the $ i^{th} $ independent variable is not correlated to the remaining ones, meaning that multicollinearity does not exist.\n",
    "\n",
    "In general terms,\n",
    "\n",
    "- VIF equal to 1 = variables are not correlated\n",
    "- VIF between 1 and 5 = variables are moderately correlated \n",
    "- VIF greater than 5 = variables are highly correlated\n",
    "\n",
    "The higher the VIF, the higher the possibility that multicollinearity exists, and further research is required. When VIF is higher than 10, there is significant multicollinearity that needs to be corrected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d15dc8",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba177827",
   "metadata": {},
   "source": [
    "# Curated Articles - Introduction to Supervised Learning and Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912fa5b0",
   "metadata": {},
   "source": [
    "- [Linear Regression](https://www.knowledgehut.com/blog/data-science/linear-regression-for-machine-learning): This article explains the linear regression algorithm along with the underlying assumptions. It talks about the various performance measures used to evaluate the model.\n",
    "\n",
    "- [Maximum Likelihood Estimation](https://brilliant.org/wiki/maximum-likelihood-estimation-mle/): This article explains the concept of maximum likelihood estimation and why it is used in machine learning with the help of examples.\n",
    "\n",
    "- [Empirical Risk Minimization](https://prateekvjoshi.com/2017/08/19/what-is-empirical-risk-minimization/): This article gives an intuition behind empirical risk minimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fe1624",
   "metadata": {},
   "source": [
    "------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
