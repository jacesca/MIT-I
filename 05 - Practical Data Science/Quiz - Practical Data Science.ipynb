{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0707d5cd",
   "metadata": {},
   "source": [
    "# Quiz - Practical Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0598a805",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9649691f",
   "metadata": {},
   "source": [
    "### 1. Decision Trees can be used to to solve ________.\n",
    "* Regression problems\n",
    "* Classification problems\n",
    "* **Regression as well as Classification problems** $\\checkmark$\n",
    "* Neither Regression nor Classification problems\n",
    "\n",
    "> The decision tree algorithm can be used to solve both kinds of problems - classification as well as regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e6737a",
   "metadata": {},
   "source": [
    "### 2. How is entropy related to the purity of the node?\n",
    "* Higher the value of entropy, higher is the purity of the node\n",
    "* **Lower the value of entropy, higher is the purity of the node** $\\checkmark$\n",
    "* Depends on the tree\n",
    "* Entropy is not a measure of purity of the node\n",
    "\n",
    "> Entropy is the measure of purity (or impurity) in a decision tree. The lower the entropy, the higher is the purity of the node and vice versa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eea28a0",
   "metadata": {},
   "source": [
    "### 3. Which of the following is/are the advantages(s) of decision tree?\n",
    "A) It requires little data preparation\n",
    "B) It can handle both categorical and numerical data\n",
    "C) A small change in the training data will result in a large change in the tree\n",
    "\n",
    "* Only A\n",
    "* **A and B** $\\checkmark$\n",
    "* B and C\n",
    "* A and C\n",
    "\n",
    "> The advantages of a decision tree are:\n",
    "> * It requires little data preparation\n",
    "> * Decision trees can handle both numerical and categorical data\n",
    "> * One of the main disadvantages of the decision tree is that a small change in the training data can result in a large change in the tree and consequently the final predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c52985",
   "metadata": {},
   "source": [
    "### 4.  _______ is a technique that reduces the size of decision trees by removing branches of the trees to avoid overfitting in a fully grown decision tree.\n",
    "* Cross-validation\n",
    "* **Pruning** $\\checkmark$\n",
    "* Test-Train Splitting\n",
    "* Bootstrapping\n",
    "\n",
    "> Pruning is a process of reducing the size of the tree so that it can become simpler and generalize better on unseen data. In the pruning process, the nodes that are adding the least information to the model are pruned/removed in order to avoid overfitting and improve the model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddc747f",
   "metadata": {},
   "source": [
    "### 5. The process of using multiple data samples, generated by random sampling with replacement, from the original dataset to create multiple models and aggregating their predictions is called _______.\n",
    "* Pruning\n",
    "* Clustering\n",
    "* **Bagging** $\\checkmark$\n",
    "* Out of bag errors\n",
    "\n",
    "> In bagging (bootstrap + aggregation), various datasets are created, by random sampling with replacement, and on these different datasets, models are trained. Then, the prediction of all the models is combined to get the final prediction by the bagging model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86a6737",
   "metadata": {},
   "source": [
    "### 6. In general, which of the following is/are the advantage(s) of ensemble techniques?\n",
    "A) Better Prediction\n",
    "B) Lower time of execution\n",
    "C) Simpler than the base model\n",
    "\n",
    "* **Only A** $\\checkmark$\n",
    "* B and C\n",
    "* A and B\n",
    "* Only C\n",
    "\n",
    "> The ensemble models combine many base models' predictions to get a final prediction, therefore:\n",
    "> 1. They are generally more accurate than their base models.\n",
    "> 2. As they combine many models they have a higher time of execution.\n",
    "> 3. They are more complex than the base model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecf8590",
   "metadata": {},
   "source": [
    "### 7. In a regression problem, for a new test data point, the final prediction by a Random Forest is done by taking the _________ \n",
    "* mode of the individual predictions\n",
    "* minimum of individual predictions\n",
    "* **average of individual predictions** $\\checkmark$\n",
    "* median of individual predictions\n",
    "\n",
    "> Random forest regression is a bit different from the classification. In classification where we take the mode of the predictions made by the different models, in regression the mean of the predictions are taken. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d305ae80",
   "metadata": {},
   "source": [
    "### 8. Which of the following can be component(s) of a Time Series?\n",
    "* Trend\n",
    "* Seasonality\n",
    "* Noise\n",
    "* **All of the above** $\\checkmark$\n",
    "\n",
    "> Trend, seasonality, and noise are components of a time series. The trend shows the variability of the feature over a period of time, if it is increasing with time, then it is a positive trend and if it is decreasing, then it is a negative trend.\n",
    "> \n",
    "> Seasonality shows the seasonal behavior of the variable. If it is showing some pattern for a specific period of time, then it is seasonal.\n",
    "> \n",
    "> Noise is random fluctuations in the time series that cannot be captured by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ae0c70",
   "metadata": {},
   "source": [
    "### 9. Which of the following is true for an autoregressive model?\n",
    "* In an autoregressive model, the value from a time series is regressed on future values from that same time series\n",
    "* **In an autoregressive model, the value from a time series is regressed on previous values from that same time series** $\\checkmark$\n",
    "* In an autoregressive model, the value from a time series is regressed on previous values from a different time series\n",
    "* In an autoregressive model, the value from a time series is regressed on future values from a different time series\n",
    "\n",
    "> In an autoregression model, the target value is the current timestamp value and the input features are the previous timestamp values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7f2451",
   "metadata": {},
   "source": [
    "### 10. When do you say that a Time Series is white noise?\n",
    "* When it has a constant mean of zero, a constant variance and there is a correlation between its values at different times\n",
    "* **When it has a constant mean of zero, a constant variance and no correlation between its values at different times** $\\checkmark$\n",
    "* When it has a constant mean of one, a constant variance of zero and no correlation between its values at different times\n",
    "* None of the above\n",
    "\n",
    "> A time series is said to have white noise when the mean of the series is zero, the variance is constant and no auto-correlation is there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c416db07",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
